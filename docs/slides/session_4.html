<!DOCTYPE html>
<html lang="en"><head>
<script src="session_4_files/libs/clipboard/clipboard.min.js"></script>
<script src="session_4_files/libs/quarto-html/tabby.min.js"></script>
<script src="session_4_files/libs/quarto-html/popper.min.js"></script>
<script src="session_4_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="session_4_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="session_4_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="session_4_files/libs/quarto-html/quarto-syntax-highlighting-3aa970819e70fbc78806154e5a1fcd28.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-99.9.9">

  <title>Session 4: Variable Selection</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="session_4_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="session_4_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="session_4_files/libs/revealjs/dist/theme/quarto-5c16f98d3e415a13fabd7d88805bbf19.css">
  <link href="session_4_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="session_4_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="session_4_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="session_4_files/libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="session_4_files/libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="session_4_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Session 4: Variable Selection</h1>
  <p class="subtitle">Model Selection and Model Simplification</p>

<div class="quarto-title-authors">
</div>

</section>
<section id="the-variable-selection-problem" class="slide level2">
<h2>The Variable Selection Problem</h2>
<p>We have an outcome <span class="math inline">\(y\)</span> and a large set of candidate predictors <span class="math inline">\(\mathbf{x} = (x_1, x_2, \ldots, x_p)\)</span>.</p>
<p>The goal is to identify which subset of predictors should enter the model.</p>
<p>This problem is ubiquitous in empirical research. Theory suggests many potential predictors. Sample size limits the number of parameters we can reliably estimate. Inclusion of irrelevant predictors inflates variance. Exclusion of relevant predictors inflates bias.</p>
<h3 id="this-session">This session</h3>
<p>We examine why stepwise selection is problematic. We explore all-subsets selection with information criteria. We introduce regularization methods that perform continuous shrinkage rather than discrete selection.</p>
</section>
<section id="why-not-just-include-everything" class="slide level2">
<h2>Why Not Just Include Everything?</h2>
<p>Consider a model with <span class="math inline">\(p\)</span> candidate predictors and sample size <span class="math inline">\(n\)</span>.</p>
<h3 id="statistical-problems">Statistical problems</h3>
<p>Parameter estimates become unstable when <span class="math inline">\(p\)</span> is large relative to <span class="math inline">\(n\)</span>. Standard errors inflate due to multicollinearity. The model fails completely when <span class="math inline">\(p &gt; n\)</span> because the design matrix is not full rank. Degrees of freedom become <span class="math inline">\(n - p - 1\)</span>, which approaches zero as <span class="math inline">\(p\)</span> grows.</p>
<h3 id="overfitting-and-variance-inflation">Overfitting and variance inflation</h3>
<p>Each additional parameter increases model variance. The bias-variance tradeoff suggests an optimal complexity less than the full model. Out-of-sample prediction error increases when too many predictors are included.</p>
<p>The consequence is that we need a principled approach to select a subset of predictors or to shrink their coefficients.</p>
</section>
<section id="stepwise-selection-the-approach" class="slide level2">
<h2>Stepwise Selection: The Approach</h2>
<p>Stepwise selection adds or removes one predictor at a time based on a criterion.</p>
<h3 id="forward-selection">Forward selection</h3>
<p>Start with the intercept-only model. At each step, add the predictor that most improves fit according to some criterion such as AIC or p-value. Stop when no remaining predictor improves the criterion.</p>
<h3 id="backward-elimination">Backward elimination</h3>
<p>Start with the full model containing all <span class="math inline">\(p\)</span> predictors. At each step, remove the predictor whose removal least degrades fit. Stop when removing any predictor degrades the criterion.</p>
<h3 id="stepwise-bidirectional">Stepwise (bidirectional)</h3>
<p>Combine forward and backward steps. At each iteration, consider both adding and removing predictors.</p>
</section>
<section id="stepwise-selection-why-it-fails" class="slide level2">
<h2>Stepwise Selection: Why It Fails</h2>
<p>Despite being widely used, stepwise selection has severe problems.</p>
<h3 id="problem-1-overfitting-and-selection-bias">Problem 1: Overfitting and selection bias</h3>
<p>The final model is chosen to minimize training error among all paths explored. This induces selection bias: the selected model appears better than it truly is. Standard errors and p-values are invalid because they ignore the search process. Post-selection inference treats the selected model as if it were pre-specified, which is incorrect.</p>
<h3 id="problem-2-instability">Problem 2: Instability</h3>
<p>Small changes in the data can produce entirely different selected models. The order of entry is highly sensitive to sampling variability. This instability indicates that the procedure is overfitting noise rather than capturing signal.</p>
</section>
<section id="stepwise-selection-more-problems" class="slide level2">
<h2>Stepwise Selection: More Problems</h2>
<h3 id="problem-3-inflated-type-i-error">Problem 3: Inflated Type I error</h3>
<p>Because we test many hypotheses sequentially, the family-wise error rate inflates dramatically. Even with <span class="math inline">\(\alpha = 0.05\)</span> at each step, the overall error rate can exceed 0.40. This leads to including spurious predictors that have no true relationship with the outcome.</p>
<h3 id="problem-4-ignores-multicollinearity">Problem 4: Ignores multicollinearity</h3>
<p>The criterion at each step is conditional on the current model. Correlated predictors can arbitrarily enter or not enter based on noise. The procedure does not account for joint effects or redundancy among predictors.</p>
<h3 id="consequence">Consequence</h3>
<p>Stepwise selection is not a valid method for inference or for reliable prediction. It is exploration, not confirmation.</p>
</section>
<section id="demonstrating-stepwise-instability" class="slide level2">
<h2>Demonstrating Stepwise Instability</h2>
<h3 id="setup">Setup</h3>
<p>Generate data where no predictors are truly related to the outcome. Fit forward stepwise selection based on AIC.</p>
<h3 id="what-happens">What happens?</h3>
<p>Despite all predictors being pure noise, stepwise will select a subset. The selected model will have low p-values and good training fit. Repeating on a new sample from the same population produces a completely different selected model.</p>
<h3 id="interpretation">Interpretation</h3>
<p>The selected model is entirely spurious. The procedure capitalizes on chance correlations in the training data. This demonstrates that stepwise can produce confident but wrong conclusions.</p>
<p>We will demonstrate this empirically in the workshop using simulation.</p>
</section>
<section id="all-subsets-selection-with-aic" class="slide level2">
<h2>All-Subsets Selection with AIC</h2>
<p>An alternative to stepwise is to fit all possible subsets and rank by AIC.</p>
<h3 id="procedure">Procedure</h3>
<p>With <span class="math inline">\(p\)</span> candidate predictors, there are <span class="math inline">\(2^p\)</span> possible models (including and excluding each predictor). Fit all <span class="math inline">\(2^p\)</span> models. Calculate AIC for each model. Rank models by AIC and identify those with <span class="math inline">\(\Delta \text{AIC} &lt; 2\)</span>.</p>
<h3 id="advantages-over-stepwise">Advantages over stepwise</h3>
<p>All-subsets is deterministic: the best model by AIC is guaranteed to be found. There is no arbitrary path dependence. We can identify multiple competitive models rather than forcing a single selection.</p>
</section>
<section id="all-subsets-limitations" class="slide level2">
<h2>All-Subsets: Limitations</h2>
<h3 id="computational-cost">Computational cost</h3>
<p>Fitting <span class="math inline">\(2^p\)</span> models becomes infeasible for large <span class="math inline">\(p\)</span>. For <span class="math inline">\(p = 20\)</span>, we must fit over 1 million models. For <span class="math inline">\(p = 30\)</span>, over 1 billion models.</p>
<h3 id="selection-bias-remains">Selection bias remains</h3>
<p>Even with all-subsets AIC, post-selection inference is invalid. Standard errors and p-values for the selected model are too optimistic. The best AIC among <span class="math inline">\(2^p\)</span> models will appear spuriously good when all models are equally bad.</p>
<h3 id="practical-constraint">Practical constraint</h3>
<p>All-subsets is feasible only when <span class="math inline">\(p\)</span> is small, typically <span class="math inline">\(p &lt; 15\)</span>. For larger <span class="math inline">\(p\)</span>, we need alternative methods.</p>
</section>
<section id="regularization-a-different-approach" class="slide level2">
<h2>Regularization: A Different Approach</h2>
<p>Rather than selecting a subset, regularization shrinks coefficient estimates toward zero.</p>
<p>The general form is:</p>
<p><span class="math display">\[\hat{\beta}_{\text{reg}} = \arg\min_{\beta} \left\{ \sum_{i=1}^{n}(y_i - \mathbf{x}_i'\beta)^2 + \lambda \cdot \text{Penalty}(\beta) \right\}\]</span></p>
<p>where <span class="math inline">\(\lambda \geq 0\)</span> controls the strength of the penalty.</p>
<p>The penalty term discourages large coefficient values. As <span class="math inline">\(\lambda\)</span> increases, coefficients shrink toward zero. When <span class="math inline">\(\lambda = 0\)</span>, we recover ordinary least squares. When <span class="math inline">\(\lambda \to \infty\)</span>, all coefficients approach zero.</p>
<p>This approach is continuous rather than discrete: coefficients shrink smoothly rather than being included or excluded.</p>
</section>
<section id="ridge-regression-l2-penalty" class="slide level2">
<h2>Ridge Regression (L2 Penalty)</h2>
<p>Ridge regression uses an L2 penalty on the coefficient magnitudes:</p>
<p><span class="math display">\[\hat{\beta}_{\text{ridge}} = \arg\min_{\beta} \left\{ \sum_{i=1}^{n}(y_i - \mathbf{x}_i'\beta)^2 + \lambda \sum_{j=1}^{p}\beta_j^2 \right\}\]</span></p>
<p>The penalty is <span class="math inline">\(\lambda \|\beta\|_2^2 = \lambda \sum_{j=1}^{p}\beta_j^2\)</span>.</p>
<h3 id="properties">Properties</h3>
<p>Ridge shrinks all coefficients toward zero but never sets any exactly to zero. It performs shrinkage, not selection. It is particularly effective when predictors are correlated because it distributes coefficient mass among correlated predictors. Ridge has a closed-form solution: <span class="math inline">\(\hat{\beta}_{\text{ridge}} = (\mathbf{X}'\mathbf{X} + \lambda \mathbf{I})^{-1}\mathbf{X}'\mathbf{y}\)</span>.</p>
<p>The addition of <span class="math inline">\(\lambda \mathbf{I}\)</span> stabilizes the inverse, allowing estimation even when <span class="math inline">\(p &gt; n\)</span>.</p>
</section>
<section id="lasso-l1-penalty" class="slide level2">
<h2>Lasso (L1 Penalty)</h2>
<p>Lasso uses an L1 penalty on the absolute coefficient values:</p>
<p><span class="math display">\[\hat{\beta}_{\text{lasso}} = \arg\min_{\beta} \left\{ \sum_{i=1}^{n}(y_i - \mathbf{x}_i'\beta)^2 + \lambda \sum_{j=1}^{p}|\beta_j| \right\}\]</span></p>
<p>The penalty is <span class="math inline">\(\lambda \|\beta\|_1 = \lambda \sum_{j=1}^{p}|\beta_j|\)</span>.</p>
<h3 id="properties-1">Properties</h3>
<p>Lasso performs both shrinkage and selection. It sets some coefficients exactly to zero, producing a sparse model. The L1 penalty has a geometric property that induces sparsity: the constraint region has corners where some coefficients equal zero. Lasso does not have a closed-form solution and requires iterative optimization.</p>
<h3 id="when-to-use-lasso">When to use lasso</h3>
<p>Lasso is preferred when we believe many predictors are irrelevant. It produces interpretable models with a subset of predictors. It is effective for high-dimensional problems where <span class="math inline">\(p\)</span> is large.</p>
</section>
<section id="elastic-net" class="slide level2">
<h2>Elastic Net</h2>
<p>Elastic net combines L1 and L2 penalties:</p>
<p><span class="math display">\[\hat{\beta}_{\text{enet}} = \arg\min_{\beta} \left\{ \sum_{i=1}^{n}(y_i - \mathbf{x}_i'\beta)^2 + \lambda \left[ \alpha \sum_{j=1}^{p}|\beta_j| + (1-\alpha) \sum_{j=1}^{p}\beta_j^2 \right] \right\}\]</span></p>
<p>The parameter <span class="math inline">\(\alpha \in [0, 1]\)</span> controls the mix between lasso (<span class="math inline">\(\alpha = 1\)</span>) and ridge (<span class="math inline">\(\alpha = 0\)</span>).</p>
<h3 id="why-elastic-net">Why elastic net?</h3>
<p>Lasso can select at most <span class="math inline">\(n\)</span> predictors when <span class="math inline">\(p &gt; n\)</span>. Lasso tends to select only one predictor from a group of correlated predictors. Ridge includes all predictors but does not perform selection.</p>
<p>Elastic net inherits advantages of both: it performs selection like lasso but handles correlated predictors more stably like ridge.</p>
</section>
<section id="choosing-the-penalty-parameter-lambda" class="slide level2">
<h2>Choosing the Penalty Parameter <span class="math inline">\(\lambda\)</span></h2>
<p>The penalty parameter <span class="math inline">\(\lambda\)</span> controls the bias-variance tradeoff.</p>
<p>Small <span class="math inline">\(\lambda\)</span> means little shrinkage, giving low bias but high variance. Large <span class="math inline">\(\lambda\)</span> means heavy shrinkage, giving high bias but low variance.</p>
<p>We select <span class="math inline">\(\lambda\)</span> by cross-validation.</p>
<h3 id="procedure-1">Procedure</h3>
<p>Specify a grid of candidate <span class="math inline">\(\lambda\)</span> values, such as <span class="math inline">\(\lambda \in \{0.001, 0.01, 0.1, 1, 10, 100\}\)</span>. For each <span class="math inline">\(\lambda\)</span>, compute k-fold cross-validation error. Select <span class="math inline">\(\lambda\)</span> that minimizes CV error. Refit the model on the full data using the selected <span class="math inline">\(\lambda\)</span>.</p>
<p>This approach estimates out-of-sample performance for each <span class="math inline">\(\lambda\)</span> and selects the value that balances bias and variance optimally.</p>
</section>
<section id="comparing-methods" class="slide level2">
<h2>Comparing Methods</h2>
<h3 id="stepwise-selection">Stepwise selection</h3>
<p>Fast and widely used. Produces a single selected model. Severely biased: overfits and produces invalid inference. Unstable: different data produce different selections.</p>
<h3 id="all-subsets-with-aic">All-subsets with AIC</h3>
<p>Deterministic and exhaustive. Identifies multiple competitive models. Computationally infeasible for <span class="math inline">\(p &gt; 15\)</span>. Still suffers from selection bias.</p>
<h3 id="regularization-lasso-ridge-elastic-net">Regularization (lasso, ridge, elastic net)</h3>
<p>Handles high-dimensional problems where <span class="math inline">\(p\)</span> is large or even <span class="math inline">\(p &gt; n\)</span>. Performs continuous shrinkage rather than discrete selection. Requires cross-validation to choose <span class="math inline">\(\lambda\)</span>. Introduces bias but reduces variance, improving prediction.</p>
</section>
<section id="practical-recommendations" class="slide level2">
<h2>Practical Recommendations</h2>
<h3 id="when-p-is-small-p-10">When <span class="math inline">\(p\)</span> is small (<span class="math inline">\(p &lt; 10\)</span>)</h3>
<p>Use all-subsets selection with AICc. Report all competitive models with <span class="math inline">\(\Delta \text{AICc} &lt; 2\)</span>. Consider model averaging (Session 5).</p>
<h3 id="when-p-is-moderate-10-p-30">When <span class="math inline">\(p\)</span> is moderate (<span class="math inline">\(10 &lt; p &lt; 30\)</span>)</h3>
<p>Use lasso or elastic net with cross-validation. Examine the stability of selected variables by repeating on bootstrap samples. Report coefficient paths showing how selection changes with <span class="math inline">\(\lambda\)</span>.</p>
<h3 id="when-p-is-large-p-30-or-p-n">When <span class="math inline">\(p\)</span> is large (<span class="math inline">\(p &gt; 30\)</span>) or <span class="math inline">\(p &gt; n\)</span></h3>
<p>Use elastic net with cross-validation. Interpret selected variables cautiously: selection is unstable. Focus on prediction performance rather than inference.</p>
<h3 id="never">Never</h3>
<p>Do not use stepwise selection for inference. Do not report p-values from a stepwise-selected model without acknowledging selection bias.</p>
</section>
<section id="coefficient-paths" class="slide level2">
<h2>Coefficient Paths</h2>
<p>A useful diagnostic is to plot coefficient estimates as a function of <span class="math inline">\(\lambda\)</span>.</p>
<p>For lasso and elastic net, this shows: - Which predictors enter the model first (at small <span class="math inline">\(\lambda\)</span>). - Which predictors remain in the model at moderate <span class="math inline">\(\lambda\)</span>. - How coefficients shrink continuously as <span class="math inline">\(\lambda\)</span> increases.</p>
<p>Variables that enter early and remain stable across a range of <span class="math inline">\(\lambda\)</span> are more reliable. Variables that enter late or are unstable are likely noise.</p>
<p>We will construct these plots in the workshop using the glmnet package.</p>
</section>
<section id="inference-after-selection" class="slide level2">
<h2>Inference After Selection</h2>
<h3 id="the-problem">The problem</h3>
<p>Standard errors and confidence intervals from a selected model are too narrow. P-values are too small because they do not account for the search process. This applies to stepwise, all-subsets, and regularization.</p>
<h3 id="approaches-to-valid-inference">Approaches to valid inference</h3>
<p>Use data splitting: select the model on one half of the data, perform inference on the other half. Use post-selection inference methods, such as selective inference or the bootstrap. Report that the model was data-selected and interpret coefficients cautiously. Focus on prediction performance via cross-validation rather than p-values.</p>
<h3 id="practical-advice">Practical advice</h3>
<p>If the goal is inference, pre-specify the model before seeing the data. If the model is data-selected, acknowledge this and do not over-interpret p-values.</p>
</section>
<section id="looking-ahead" class="slide level2">
<h2>Looking Ahead</h2>
<h3 id="this-session-1">This session</h3>
<p>We covered the variable selection problem and methods for choosing predictors.</p>
<h3 id="next-session">Next session</h3>
<p>We will cover model averaging: rather than selecting a single model, we average predictions across multiple models weighted by their empirical support. This acknowledges model uncertainty and often improves prediction.</p>
<h3 id="key-concepts-established">Key concepts established</h3>
<p>Stepwise selection is problematic due to overfitting, instability, and invalid inference. All-subsets selection is exhaustive but computationally limited. Regularization methods (lasso, ridge, elastic net) perform continuous shrinkage and handle high-dimensional problems. Cross-validation is used to select the penalty parameter <span class="math inline">\(\lambda\)</span>.</p>

</section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">
<p><a href="https://mark-andrews.github.io/msms/">mark-andrews.github.io/msms/</a></p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="session_4_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="session_4_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="session_4_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="session_4_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="session_4_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="session_4_files/libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="session_4_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="session_4_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="session_4_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="session_4_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="session_4_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
          const outerScaffold = trigger.parentElement.cloneNode(true);
          const codeEl = outerScaffold.querySelector('code');
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp('/' + window.location.host + '/');
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>